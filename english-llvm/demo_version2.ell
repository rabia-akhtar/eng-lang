/* demo code for English Language */
/* TODO: string splitAt function */
/* TODO: for some of the c linked functions and types, change the name to match the function, file, strlen, strcmp */
/* TODO: add a way to catch file io exceptions */
/* TODO: figure out max size we will read in and how to convert the buffer to a string */
/* TODO: structs */
/* TODO: build hashmap-like data structure, not high priority. */

/* function finds top twenty (this value TBD) most relevant words in a text document */
string [] find_relevant(string file_name){

	file fp; // call it "file" if you're using it as a wrapper around C API.
    fp = open(file_name, "r"); // what if there are newlines? tabs? why binary?
   
    

/* maximum size of essay we can process, TBD */
string [2000] buffer; // what do you mean maximum? is this array notation?

fread(buffer, 2000, 1, fp);

/* todo */
string doc = toString(buffer); // converting a string[2000] to a string? confused.

int size = string_length(doc); // characters? words? call it strlen if it's the same function

string [size] words; // words[size]? or [size] words

/* todo */
words = doc.split_at(" "); // Is split_at going to be a built-in? How are you storing words? What is the type of words?

/* count the frequency of each word in the text document and store in count */
int [size] count; // why [size]? what if there are repeat words? -> we don't know

int i;
int j;
int found = 0;
string current;

for (i = 0; i < size; i = i + 1){
	current = words[i]; // redefine current every iteration?
	for (j = 0; j< size; j = j+1){
	    /* check if same word has been found */
		if (found == 0){
    		if (string_compare(current, words[j]) == 0){ // not at all necessary, but not current == words[j]? just call it strcmp if it's the same function
    			found = 1;
    			count [j]++;
    		}
		}
	}
	found = 0;
}

/* find top twenty words */

struct WordCount{
    string [20] top_words;
    int[20] top_counts;
} wordcount;

int max = 0;
int max_index = 0; // type?
string max_word;
int i_top = 0;
int k;

for (k = 0; k< 20; k = k +1){
	for (i = 0; i < size; i = i + 1){
		if (max < count[i]){
			int present = 0;
			for (j = 0; j<20; j = j+1){ // not very efficient. could use heap or hash map structure.
				/* check if value already put in top words */
				if (count[i] == wordcount.top_counts[j]){	    					if (string_compare(words[i] == wordcount.top_words[j])){

						present = 1;
				}
				}

			}

			if(present == 0){ 
				max_index = i;
				max = count[i];

			}
	}
	}

	top_words[k] = words[max_index];
	top_counts[k] = count[max_index];
	i_top++;
	max = 0;


    	}
    close(fp);

    return top_words;

    }

/* check for simlarity of content between two files, returns percentage similar.

float check_similar(string file1, string file2){

	/* find relevant words in each document */
	/* the hard coded numbers can be changed or made input */ // input would be ideal
	string [20] relevant1 = find_relevant(file1); // [20]? what if there are more words? graceful exit?
	string [20] relevant2 = find_relevant(file2);

	/* check for similarity in content */
	int i;
	int j;
	float similar = 0;
	for(i = 0; i< 20; i = i + 1){
		for(j = 0; j< 20; j = j + 1){
			if(string_compare(relevant1[i], relevant2[i]) == 0){				similar = similar + 1; 
			}
		}
	}

	what if the words are in different positions? LCS (longest common substring) or average length of substrings or average percentage of longest common substrings with lengths > 1 would be interesting. Even if it's the exact same document offset by 1 word, this algorithm won't catch anything. 

	return (similar/20.0);

}

int main()
{
  return 0; // to be implemented?
}
